{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the Vaani Demo Notebook.\n",
    "#### Please make sure you have all the libraries installed (refer to `requirements.txt` document for help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "MAX_LENGTH = 256\n",
    "# CUDA suport test\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing word2vec model\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /models/bhagvadgita/BEST_max_pooled_autoencoder.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Amee Madhani\\vaani\\backend\\DemoNotebook.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# initializing all background prep that goes into prediction (open this cell for autopsy)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# loading the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m demomodel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m/models/bhagvadgita/BEST_max_pooled_autoencoder.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m demoencoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(demomodel\u001b[39m.\u001b[39minput, demomodel\u001b[39m.\u001b[39mlayers[\u001b[39m5\u001b[39m]\u001b[39m.\u001b[39moutput)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m gitaDemo \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../dataset/bhagvadgita_encoded.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Amee Madhani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Amee Madhani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\legacy\\save.py:227\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    226\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    232\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    233\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    234\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at /models/bhagvadgita/BEST_max_pooled_autoencoder.h5"
     ]
    }
   ],
   "source": [
    "# initializing all background prep that goes into prediction (open this cell for autopsy)\n",
    "# loading the model\n",
    "demomodel = tf.keras.models.load_model('./models/bhagvadgita/BEST_max_pooled_autoencoder.h5')\n",
    "demoencoder = tf.keras.Model(demomodel.input, demomodel.layers[5].output)\n",
    "gitaDemo = pd.read_csv('../dataset/bhagvadgita_encoded.csv')\n",
    "gitaDemo = gitaDemo.drop(['Unnamed: 0'], axis=1)\n",
    "gitaDemo = gitaDemo.drop([546], axis=0)\n",
    "gitaDemo['nlp'] = [nlp(i) for i in gitaDemo['English Translation']]\n",
    "\n",
    "# function definitions\n",
    "def tensorgoBrr(df: pd.DataFrame, column: str):\n",
    "    \"\"\"this function returns tensors for max pooled, mean pooled, and all present (padded up or down to 256 vectors)\n",
    "    the return is a tuple with the order max, mean, and all tokens respectively.\"\"\"\n",
    "    maxtokens = []\n",
    "    meantokens = []\n",
    "    alltokens = []\n",
    "\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        tokenlist = np.array([token.vector.get() for token in doc])\n",
    "        maxnormlist = np.array([float(token.vector_norm) for token in doc])\n",
    "        if MAX_LENGTH - tokenlist.shape[0] > 0:\n",
    "            constructarr = np.zeros((MAX_LENGTH - tokenlist.shape[0], 300))\n",
    "            alltokens.append(np.append(tokenlist, constructarr, axis=(0)))\n",
    "        else:\n",
    "            alltokens.append(tokenlist[:MAX_LENGTH])\n",
    "\n",
    "        maxtokens.append(np.array(tokenlist[maxnormlist.argmax()]))\n",
    "        meantokens.append(np.array(tokenlist.mean(axis=(0))))\n",
    "\n",
    "    tmaxtokens = tf.convert_to_tensor(maxtokens)\n",
    "    tmeantokens = tf.convert_to_tensor(meantokens)\n",
    "    talltokens = tf.convert_to_tensor(alltokens)\n",
    "\n",
    "    return (tmaxtokens, tmeantokens, talltokens)\n",
    "\n",
    "def find_closest_gita_verse(token):\n",
    "    start = time.time()\n",
    "    # print(\"Let me Think\", end='')\n",
    "    # time.sleep(2)\n",
    "    # print('.',end='')\n",
    "    encoding = demoencoder.predict(token, verbose=0)\n",
    "    # time.sleep(0.4)\n",
    "    vectorComp = gitaDemo.iloc[:, -6:-1].to_numpy()\n",
    "    # print('.',end='')\n",
    "    # time.sleep(0.5)\n",
    "    # similarity rating function\n",
    "    diff = np.array([np.dot(encoding, i)/(np.linalg.norm(encoding)*np.linalg.norm(i)) for i in vectorComp])\n",
    "    seriesSlice = gitaDemo.iloc[diff.argmax(), 1:4]\n",
    "    #print('.')\n",
    "    # time.sleep(0.83)\n",
    "    # return a nicely formatted string.\n",
    "    exect = time.time() - start\n",
    "    return f\"AM4's Output: Chapter {seriesSlice[0]}, Verse {seriesSlice[1]} of the Bhagvadgita, which says:\\n\\n{seriesSlice[2]}\\nTime Taken: {exect}\"\n",
    "\n",
    "def find_spacy_output(text):\n",
    "    start = time.time()\n",
    "    vector = nlp(text)\n",
    "    simArr = np.array([vector.similarity(i) for i in gitaDemo['nlp']])\n",
    "    seriesSlice = gitaDemo.iloc[simArr.argmax(), 1:4]\n",
    "    exect = time.time() - start\n",
    "    return f\"Base Vector Comparison Output: Chapter {seriesSlice[0]}, Verse {seriesSlice[1]} of the Bhagvadgita, which says:\\n\\n{seriesSlice[2]}\\nTime Taken: {exect}\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the cells, but rerun this one to experience the demo again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Input: what is the meaning of life\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensorgoBrr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Amee Madhani\\vaani\\backend\\DemoNotebook.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mWhat Troubles you, friend?\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mText Input: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m token, _, _ \u001b[39m=\u001b[39m tensorgoBrr(pd\u001b[39m.\u001b[39mDataFrame([text], columns\u001b[39m=\u001b[39m([\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])), \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(find_closest_gita_verse(token) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Amee%20Madhani/vaani/backend/DemoNotebook.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(find_spacy_output(text) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorgoBrr' is not defined"
     ]
    }
   ],
   "source": [
    "# DEMO CELL\n",
    "text = input('What Troubles you, friend?')\n",
    "print(f'Text Input: {text}' + '\\n---------------------------------')\n",
    "token, _, _ = tensorgoBrr(pd.DataFrame([text], columns=(['text'])), 'text')\n",
    "print(find_closest_gita_verse(token) + '\\n---------------------------------')\n",
    "print(find_spacy_output(text) + '\\n---------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for your time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
