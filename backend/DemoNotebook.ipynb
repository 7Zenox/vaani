{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the Vaani Demo Notebook.\n",
    "#### Please make sure you have all the libraries installed (refer to `requirements.txt` document for help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "MAX_LENGTH = 256\n",
    "# CUDA suport test\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing word2vec model\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing all background prep that goes into prediction (open this cell for autopsy)\n",
    "# loading the model\n",
    "demomodel = tf.keras.models.load_model('./models/bhagvadgita/BEST_max_pooled_autoencoder.h5')\n",
    "demoencoder = tf.keras.Model(demomodel.input, demomodel.layers[5].output)\n",
    "gitaDemo = pd.read_csv('../dataset/bhagvadgita_encoded.csv')\n",
    "gitaDemo = gitaDemo.drop(['Unnamed: 0'], axis=1)\n",
    "gitaDemo = gitaDemo.drop([546], axis=0)\n",
    "\n",
    "# function definitions\n",
    "def tensorgoBrr(df: pd.DataFrame, column: str):\n",
    "    \"\"\"this function returns tensors for max pooled, mean pooled, and all present (padded up or down to 256 vectors)\n",
    "    the return is a tuple with the order max, mean, and all tokens respectively.\"\"\"\n",
    "    maxtokens = []\n",
    "    meantokens = []\n",
    "    alltokens = []\n",
    "\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        tokenlist = np.array([token.vector.get() for token in doc])\n",
    "        maxnormlist = np.array([float(token.vector_norm) for token in doc])\n",
    "        if MAX_LENGTH - tokenlist.shape[0] > 0:\n",
    "            constructarr = np.zeros((MAX_LENGTH - tokenlist.shape[0], 300))\n",
    "            alltokens.append(np.append(tokenlist, constructarr, axis=(0)))\n",
    "        else:\n",
    "            alltokens.append(tokenlist[:MAX_LENGTH])\n",
    "\n",
    "        maxtokens.append(np.array(tokenlist[maxnormlist.argmax()]))\n",
    "        meantokens.append(np.array(tokenlist.mean(axis=(0))))\n",
    "\n",
    "    tmaxtokens = tf.convert_to_tensor(maxtokens)\n",
    "    tmeantokens = tf.convert_to_tensor(meantokens)\n",
    "    talltokens = tf.convert_to_tensor(alltokens)\n",
    "\n",
    "    return (tmaxtokens, tmeantokens, talltokens)\n",
    "\n",
    "def find_closest_gita_verse(token):\n",
    "    print(\"Let me Think\", end='')\n",
    "    time.sleep(2)\n",
    "    print('.',end='')\n",
    "    encoding = demoencoder.predict(token, verbose=0, reduce_retracing=True)\n",
    "    time.sleep(0.4)\n",
    "    vectorComp = gitaDemo.iloc[:, -5:].to_numpy()\n",
    "    print('.',end='')\n",
    "    time.sleep(0.5)\n",
    "    # similarity rating function\n",
    "    diff = np.array([np.dot(encoding, i)/(np.linalg.norm(encoding)*np.linalg.norm(i)) for i in vectorComp])\n",
    "    seriesSlice = gitaDemo.iloc[diff.argmax(), 1:4]\n",
    "    print('.')\n",
    "    time.sleep(0.83)\n",
    "    # return a nicely formatted string.\n",
    "    return f\"I'd say you should understand Chapter {seriesSlice[0]}, Verse {seriesSlice[1]} of the Bhagvadgita, which says:\\n\\n{seriesSlice[2]}\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the cells, but rerun this one to experience the demo again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You seen wisdom about: when is life complete?\n",
      "Let me Think...\n",
      "I'd say you should understand Chapter 4, Verse 14 of the Bhagvadgita, which says:\n",
      "\n",
      "The Lord continued: O Arjuna, since I, the immortal Lord, have no cravings for the fruits of action, I do not desire the reward of Karma. Therefore those who know me well are not affected or bound by Karma (action).\n"
     ]
    }
   ],
   "source": [
    "# DEMO CELL\n",
    "text = input('What Troubles you, friend?')\n",
    "print(f'You seen wisdom about: {text}')\n",
    "token, _, _ = tensorgoBrr(pd.DataFrame([text], columns=(['text'])), 'text')\n",
    "print(find_closest_gita_verse(token))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
