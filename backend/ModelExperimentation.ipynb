{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is developed as a documentation for experimentation and development of a model for the sacred.ai project created by Vasu Jain, Amee Madhani, Anand Chauhan, and Ananya Chauhan as part of our university course. The project to create one or multiple model in order to answer question based on life, the universe, and everything with the knowledge of several religious texts for Hinduism, Christianity, and Islam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# verifying if cuda setup works properly\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current working approaches include looking to religious semantic searching and question-answering. The latter of these requires an extensive dataset covering a wide variety of questions and associated answers and outputs we'd be looking for, and is therefore hard to implement since we do not know if anything like that even exists (hopefully not lol)\n",
    "\n",
    "So we'd have to play around a lot with feature extraction, semantics and transformers and their encoding.e\n",
    "\n",
    "Can't do regression based linear transformations either since that, too, requires a dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just import all our datasets for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Verse</th>\n",
       "      <th>English Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arjuna's Vishada Yoga</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>Verse 1.1</td>\n",
       "      <td>Dhrtarashtra asked of Sanjaya: O SANJAYA, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arjuna's Vishada Yoga</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>Verse 1.2</td>\n",
       "      <td>Sanjaya explained: Now seeing that the army of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arjuna's Vishada Yoga</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>Verse 1.3</td>\n",
       "      <td>Behold O, Master, the mighty army of the sons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arjuna's Vishada Yoga</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>Verse 1.4</td>\n",
       "      <td>Present here are the mighty archers, peers or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arjuna's Vishada Yoga</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>Verse 1.5</td>\n",
       "      <td>Dhrishtaketu, Chekitana, and the valiant king ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Title    Chapter      Verse  \\\n",
       "0  Arjuna's Vishada Yoga  Chapter 1  Verse 1.1   \n",
       "1  Arjuna's Vishada Yoga  Chapter 1  Verse 1.2   \n",
       "2  Arjuna's Vishada Yoga  Chapter 1  Verse 1.3   \n",
       "3  Arjuna's Vishada Yoga  Chapter 1  Verse 1.4   \n",
       "4  Arjuna's Vishada Yoga  Chapter 1  Verse 1.5   \n",
       "\n",
       "                                 English Translation  \n",
       "0  Dhrtarashtra asked of Sanjaya: O SANJAYA, what...  \n",
       "1  Sanjaya explained: Now seeing that the army of...  \n",
       "2  Behold O, Master, the mighty army of the sons ...  \n",
       "3  Present here are the mighty archers, peers or ...  \n",
       "4  Dhrishtaketu, Chekitana, and the valiant king ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bhagvadgita = pd.read_csv('../dataset/gitaDataset.csv')\n",
    "quran = pd.read_csv('../dataset/quranDataset.csv')\n",
    "bible = pd.read_csv('../dataset/bibleDataset.csv')\n",
    "print(bhagvadgita.shape)\n",
    "bhagvadgita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Arjuna's Vishada Yoga\", 'Sankhya Yoga', 'Karma Yoga',\n",
       "       'Jnana-Karma-Sanyasa Yoga', 'Atma-Samyama Yoga',\n",
       "       'Jnana-Vijnana Yoga', 'Aksara-ParaBrahma Yoga',\n",
       "       'Raja-Vidya-Raja-Guhya Yoga', 'Vibhuti Yoga',\n",
       "       'Viswarupa-Darsana Yoga', 'Bhakti Yoga',\n",
       "       'Ksetra-Ksetrajna-Vibhaga Yoga', 'Gunatraya-Vibhaga Yoga',\n",
       "       'Purushottama Yoga', 'Daivasura-Sampad-Vibhaga Yoga',\n",
       "       'Shraddhatraya-Vibhaga Yoga', 'Moksha-Sanyasa Yoga'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bhagvadgita['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6236, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Surah</th>\n",
       "      <th>Ayat</th>\n",
       "      <th>Verse</th>\n",
       "      <th>Tafseer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Opening</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the name of Allah, the Beneficent, the Merc...</td>\n",
       "      <td>In the Name of God the Compassionate the Merciful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Opening</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Praise be to Allah, Lord of the Worlds,</td>\n",
       "      <td>In the Name of God the name of a thing is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Opening</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>The Beneficent, the Merciful.</td>\n",
       "      <td>The Compassionate the Merciful that is to say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Opening</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Owner of the Day of Judgment,</td>\n",
       "      <td>Master of the Day of Judgement that is the day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Opening</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Thee (alone) we worship; Thee (alone) we ask f...</td>\n",
       "      <td>You alone we worship and You alone we ask for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Surah  Ayat  \\\n",
       "0  The Opening      1     1   \n",
       "1  The Opening      1     2   \n",
       "2  The Opening      1     3   \n",
       "3  The Opening      1     4   \n",
       "4  The Opening      1     5   \n",
       "\n",
       "                                               Verse  \\\n",
       "0  In the name of Allah, the Beneficent, the Merc...   \n",
       "1            Praise be to Allah, Lord of the Worlds,   \n",
       "2                      The Beneficent, the Merciful.   \n",
       "3                      Owner of the Day of Judgment,   \n",
       "4  Thee (alone) we worship; Thee (alone) we ask f...   \n",
       "\n",
       "                                             Tafseer  \n",
       "0  In the Name of God the Compassionate the Merciful  \n",
       "1  In the Name of God the name of a thing is that...  \n",
       "2  The Compassionate the Merciful that is to say ...  \n",
       "3  Master of the Day of Judgement that is the day...  \n",
       "4  You alone we worship and You alone we ask for ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(quran.shape)\n",
    "quran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31103, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>At the first God made the heaven and the earth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was waste and without form; and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God, looking on the light, saw that it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Naming the light, Day, and the dark, Night. An...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     field  book  chapter  verse  \\\n",
       "0  1001001     1        1      1   \n",
       "1  1001002     1        1      2   \n",
       "2  1001003     1        1      3   \n",
       "3  1001004     1        1      4   \n",
       "4  1001005     1        1      5   \n",
       "\n",
       "                                                text  \n",
       "0    At the first God made the heaven and the earth.  \n",
       "1  And the earth was waste and without form; and ...  \n",
       "2  And God said, Let there be light: and there wa...  \n",
       "3  And God, looking on the light, saw that it was...  \n",
       "4  Naming the light, Day, and the dark, Night. An...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bible.shape)\n",
    "bible.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                  object\n",
       "Chapter                 int64\n",
       "Verse                   int64\n",
       "English Translation    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whatever approach we implement now we will implement first on the bhagvadgita, since it is the smallest.\n",
    "# everything else will be taken care of later lmao\n",
    "try:\n",
    "    # removing useless text and making everthing integer.\n",
    "    bhagvadgita['Verse'] = bhagvadgita['Verse'].apply(lambda x: x.split('.')[-1]).astype('int')\n",
    "    bhagvadgita['Chapter'] = bhagvadgita['Chapter'].apply(lambda x: x.split()[-1]).astype('int')\n",
    "except AttributeError:\n",
    "    # circumventing inplace problems\n",
    "    pass\n",
    "# check dtypes\n",
    "bhagvadgita.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "118\n",
      "273\n",
      "584\n"
     ]
    }
   ],
   "source": [
    "# finding the maximum amonut of words in any single shlok/verse/passage. we will model our max query length around it. maybe.\n",
    "# every book will therfore contain three tensors. max pooled, mean pooled, and all vectors with a lot of zeroes.\n",
    "max_length = 0\n",
    "for i in bhagvadgita['English Translation']:\n",
    "    if len(i.split()) > max_length:\n",
    "        max_length = len(i.split())\n",
    "print(max_length)\n",
    "for j in bible['text']:\n",
    "    if len(j.split()) > max_length:\n",
    "        max_length = len(j.split())\n",
    "print(max_length)\n",
    "for k in quran['Verse']:\n",
    "    if len(k.split()) > max_length:\n",
    "        max_length = len(k.split())\n",
    "print(max_length)\n",
    "for l in quran['Tafseer'].astype('str'):\n",
    "    if len(l.split()) > max_length:\n",
    "        max_length = len(l.split())\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 584 \n",
    "# best case, let's try smaller sizes first\n",
    "MAX_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the word2vec model that we'll be using for now.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max v/s overall vector: False \n",
      "Mean v/s overall vector: True \n",
      "Max v/s Argmax vector: False\n"
     ]
    }
   ],
   "source": [
    "# investigating if the standard vector function does max or mean pooling.\n",
    "lmaobase = np.array([token.vector.get() for token in nlp(bhagvadgita['English Translation'][0])])\n",
    "lmao = lmaobase.mean(axis=(0))\n",
    "argm = np.array([float(token.vector_norm) for token in nlp(bhagvadgita['English Translation'][0])])\n",
    "lmao1 = lmaobase[argm.argmax()]\n",
    "lmao2 = np.array(nlp(bhagvadgita['English Translation'][0]).vector.get())\n",
    "lmao3 = lmaobase.max(axis=(0))\n",
    "print(f\"Max v/s overall vector: {np.array_equal(lmao1, lmao2)} \\nMean v/s overall vector: {np.array_equal(lmao, lmao2)} \\nMax v/s Argmax vector: {np.array_equal(lmao1, lmao3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 300)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experimenting with how to make a vector with all zeroes\n",
    "# find a zero vector\n",
    "zerosample = np.array(nlp(bhagvadgita['English Translation'][0].split()[0]).vector.get())\n",
    "constructedzeros = np.zeros((300,))\n",
    "np.array_equal(constructedzeros, zerosample)\n",
    "zerosample = np.array([token.vector.get() for token in nlp(bhagvadgita['English Translation'][0])])\n",
    "constructarr = np.zeros((MAX_LENGTH - zerosample.shape[0], 300))\n",
    "hope = np.append(zerosample, constructarr, axis=(0))\n",
    "hope.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT WORKS!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can see that spacy's `en_core_web_lg` uses mean pooling. so we can make our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 15:43:24.914847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 15:43:24.917728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 15:43:24.917830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 15:43:24.917858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 15:43:24.918830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 15:43:24.918879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 15:43:24.918888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-22 15:43:24.918916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 15:43:24.918989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4043 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-03-22 15:43:25.376285: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 430080000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([700, 300]),\n",
       " TensorShape([700, 300]),\n",
       " TensorShape([700, 256, 300]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with one field, trying both max and mean pooling.\n",
    "maxtokens = []\n",
    "meantokens = []\n",
    "alltokens = []\n",
    "\n",
    "for i in bhagvadgita['English Translation']:\n",
    "    doc = nlp(i)\n",
    "    tokenlist = np.array([token.vector.get() for token in doc])\n",
    "    maxnormlist = np.array([float(token.vector_norm) for token in doc])\n",
    "    if MAX_LENGTH - tokenlist.shape[0] > 0:\n",
    "        constructarr = np.zeros((MAX_LENGTH - tokenlist.shape[0], 300))\n",
    "        alltokens.append(np.append(tokenlist, constructarr, axis=(0)))\n",
    "    else:\n",
    "        alltokens.append(tokenlist[:MAX_LENGTH])\n",
    "\n",
    "    maxtokens.append(np.array(tokenlist[maxnormlist.argmax()]))\n",
    "    meantokens.append(np.array(tokenlist.mean(axis=(0))))\n",
    "\n",
    "tmaxtokens = tf.convert_to_tensor(maxtokens)\n",
    "tmeantokens = tf.convert_to_tensor(meantokens)\n",
    "talltokens = tf.convert_to_tensor(alltokens)\n",
    "\n",
    "tmaxtokens.shape, tmeantokens.shape, talltokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting this to a function for later use:\n",
    "def tensorgoBrr(df: pd.DataFrame, column: str):\n",
    "    \"\"\"this function returns tensors for max pooled, mean pooled, and all present (padded up or down to {MAX_LENGTH} vectors)\n",
    "    the return is a tuple with the order max, mean, and all tokens respectively.\"\"\"\n",
    "    maxtokens = []\n",
    "    meantokens = []\n",
    "    alltokens = []\n",
    "\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        tokenlist = np.array([token.vector.get() for token in doc])\n",
    "        maxnormlist = np.array([float(token.vector_norm) for token in doc])\n",
    "        if MAX_LENGTH - tokenlist.shape[0] > 0:\n",
    "            constructarr = np.zeros((MAX_LENGTH - tokenlist.shape[0], 300))\n",
    "            alltokens.append(np.append(tokenlist, constructarr, axis=(0)))\n",
    "        else:\n",
    "            alltokens.append(tokenlist[:MAX_LENGTH])\n",
    "\n",
    "        maxtokens.append(np.array(tokenlist[maxnormlist.argmax()]))\n",
    "        meantokens.append(np.array(tokenlist.mean(axis=(0))))\n",
    "\n",
    "    tmaxtokens = tf.convert_to_tensor(maxtokens)\n",
    "    tmeantokens = tf.convert_to_tensor(meantokens)\n",
    "    talltokens = tf.convert_to_tensor(alltokens)\n",
    "\n",
    "    return (tmaxtokens, tmeantokens, talltokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created the tensors for all verses of the bhagvadgita. for the demo this is all that we wil be doing.\n",
    "\n",
    "Bear in mind that the tensor with all adjusted vectors for the Bhagvadgita alone is over 400 MB, which, considering my system VRAM of 8GB, might become a computational power problem later down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c84e5e0094cb720dcb83feadb93e4b30c9501c23e2a5cb9df6091d8c79ac21d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
